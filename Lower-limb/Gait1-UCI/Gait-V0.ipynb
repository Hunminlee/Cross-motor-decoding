{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 3 different exercises: sitting, standing and walking in the muscles: biceps femoris, vastus medialis, rectus femoris and semitendinosus addition to goniometry in the exercises.\n",
    "\n",
    "Each data file contains 5 columns, organized as follows.\n",
    "Segment\tLower Limb\n",
    "Channel\tCh1\tCh2\tCh3\tCh4\tCh5\n",
    "Muscle\tRF\tBF\tVM\tST\tFX\n",
    "Column\t0\t1\t2\t3\t4\n",
    "\n",
    "\n",
    "- 2.1. Protocol:\n",
    "22 male subjects , 11 with different knee abnormalities previously diagnosed by a professional. They undergo three movements to analyze the behavior associated with the knee muscle , gait , leg extension from a sitting position , and flexion of the leg up. The acquisition process was conducted with 4 electrodes ( Vastus Medialis , semitendinosus , biceps femoris and rectus femoris ) and the goniometer in the knee .\n",
    "\n",
    "- 2.2.\tInstrumentation\n",
    "Datalog equipment was used MWX8 by Biometrics of 8 digital channels and 4 analog channels , of which 4 for sampling were used SEMG and 1 for goniometry, these data were acquired directly to the computer MWX8 internal storage with microSD card and transmitted in Real-time Datalog software through bluetooth adapter , 14-bit resolution and sampling frequency of 1000Hz .\n",
    "\n",
    "- 2.3.\tData configuration:\n",
    "The total number of electrodes is 4, corresponding to the time series one for each channel (1 to 4). Each series contains ~ 5 shares or motion repetitions for each subject.\n",
    "\n",
    "## No sessions exist\n",
    "\n",
    "\n",
    "# Intra-subject\n",
    "\n",
    "### Obj. 1\n",
    "1. Subject 별로 train-test split 써서 학습 / 테스트\n",
    "2. feature extraction using multiple features / windows\n",
    "- use normal only\n",
    "\n",
    "### Obj. 2\n",
    "- Cross-subject 시에 사용 가능 -> few-shot adaptation\n",
    "\n",
    "### Obj. 3\n",
    "- Federated Learning with multiple subjects"
   ],
   "id": "e128dbbec5188404"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T20:08:35.936049Z",
     "start_time": "2025-08-19T20:08:35.734258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def call_data(base_path, sub_lst, sub_idx):\n",
    "    data = pd.read_csv(base_path+sub_lst[sub_idx])\n",
    "    return data\n",
    "\n",
    "def data_setup(lst_normal, path_normal):\n",
    "    subjects_data = defaultdict(list)\n",
    "    subjects_label = defaultdict(list)\n",
    "\n",
    "    for s_idx, filename in enumerate(lst_normal):\n",
    "        name = filename.lower()\n",
    "        subject_id = name.split(\"n\")[0]\n",
    "        data = call_data(path_normal, lst_normal, s_idx).to_numpy()  # (num_samples, num_channels)\n",
    "\n",
    "        windows = processing.sliding_window(data, window_size, step_size)  # (num_windows, win_len, ch)\n",
    "\n",
    "        if \"standing\" in name: label = 0\n",
    "        elif \"gait\" in name: label = 1\n",
    "        elif \"sitting\" in name: label = 2\n",
    "        else: label = -1\n",
    "\n",
    "        labels = np.full(len(windows), label)\n",
    "\n",
    "        subjects_data[subject_id].append(windows)\n",
    "        subjects_label[subject_id].append(labels)\n",
    "\n",
    "    return subjects_data, subjects_label\n",
    "\n",
    "\n",
    "\n",
    "def get_X_y(X, y):\n",
    "    all_X, all_y = [], []\n",
    "\n",
    "    #for subject_id in subjects_data.keys():\n",
    "    data_list = X\n",
    "    label_list = y\n",
    "\n",
    "    for data, labels in zip(data_list, label_list):\n",
    "        for w, label in zip(data, labels):  # w: (win_len, ch)\n",
    "            feat = processing.extract_features(w)  # (num_channels*5,)\n",
    "            all_X.append(feat)\n",
    "            all_y.append(label)\n",
    "\n",
    "    all_X, all_y = np.array(all_X), np.array(all_y)   # (N, num_channels*5)\n",
    "    all_X = all_X.reshape(-1, num_channels, num_features, 1)\n",
    "\n",
    "    return all_X, all_y"
   ],
   "id": "4456a04ff757eea3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-19T20:12:29.570699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../Shared')\n",
    "import processing, Model, Visualization\n",
    "\n",
    "\n",
    "path_abnormal = \"../../../Data/Gait1/Abnormal/\"\n",
    "path_normal = \"../../../Data/Gait1/normal/\"\n",
    "\n",
    "lst_abnormal = os.listdir(path_abnormal)\n",
    "lst_normal = os.listdir(path_normal)\n",
    "\n",
    "window_size, step_size = 200, 10\n",
    "num_channels, num_features = 5, 5  # we extracted 5 features per channel\n",
    "\n",
    "\n",
    "subjects_data, subjects_label = data_setup(lst_normal, path_normal)\n",
    "\n",
    "for subject_id in subjects_data.keys():\n",
    "    X, y = get_X_y(X=subjects_data[subject_id], y=subjects_label[subject_id])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = Model.build_model(input_shape=X_train.shape[1:], num_classes=len(np.unique(y)))\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128, verbose=0)\n",
    "    #Visualization.learning_plot(history)\n",
    "    print(f\"Sub ID {subject_id} : val acc => {np.max(history.history['val_accuracy'])*100:.2f}%\")"
   ],
   "id": "7edb41754880e276",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hml76\\PycharmProjects\\Cross-motor-decoding\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub ID 10 : val acc => 100.00%\n",
      "Sub ID 11 : val acc => 100.00%\n",
      "Sub ID 1 : val acc => 100.00%\n",
      "Sub ID 2 : val acc => 100.00%\n",
      "Sub ID 3 : val acc => 98.63%\n",
      "Sub ID 4 : val acc => 99.31%\n",
      "Sub ID 5 : val acc => 100.00%\n",
      "Sub ID 6 : val acc => 100.00%\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4d592f3a864509",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "968513d71f60c327",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2352e1aad2bd66fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "90391df738328cc6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
