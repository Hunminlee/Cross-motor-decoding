{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:35:20.414138Z",
     "start_time": "2025-08-21T12:35:17.318118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "sys.path.append('../Shared')\n",
    "import processing, Model, Visualization, modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_label_from_filename(fname):\n",
    "    for cls, label in class_to_label.items():\n",
    "        if cls in fname:\n",
    "            return label\n",
    "    return None  # if no class found\n",
    "\n",
    "def get_data_all_at_once(SUB, data_lst, label_lst):\n",
    "    dataset, labels = [], []\n",
    "\n",
    "    for l, d in zip(label_lst, data_lst):\n",
    "        data = pd.read_csv(base_path + SUB + \"/\" + d)\n",
    "        data = data.iloc[:, 1:]   # 첫 column(time) 제거\n",
    "        label = get_label_from_filename(l)\n",
    "        labels.append(np.array([label] * data.shape[0]))\n",
    "        dataset.append(data)\n",
    "        #print(\"\\t\", l, d, \" ====> \", np.array([label] * data.shape[0]).shape, data.shape)\n",
    "\n",
    "    D = np.concatenate(dataset, axis=0)\n",
    "    L = np.concatenate(labels, axis=0)\n",
    "    #print(D.shape, L.shape)\n",
    "\n",
    "    balanced_idx = modules.Downsample_to_balance_class(L)\n",
    "    X_emg_bal, y_bal = D[balanced_idx], L[balanced_idx]\n",
    "    print(\"\\t Balanced EMG:\", X_emg_bal.shape, \"y:\", y_bal.shape)\n",
    "\n",
    "    num_channels = X_emg_bal.shape[1]\n",
    "\n",
    "    X_tmp, y_tmp = processing.sliding_window_with_labels(X=X_emg_bal, y=y_bal,  window_size=window_size, step_size=step_size)  # (num_windows, win_len, ch)\n",
    "\n",
    "    all_X, all_y = modules.get_X_y_ZC_only(X_tmp, y_tmp)\n",
    "    all_y = modules.y_change_to_int(all_y)\n",
    "    all_X = all_X.reshape(-1, num_channels, 1)\n",
    "\n",
    "    return all_X, all_y\n",
    "\n",
    "def get_data(sub_info, data_lst, label_lst):\n",
    "    dataset, labels = [], []\n",
    "\n",
    "    for l, d in zip(label_lst, data_lst):\n",
    "        data = pd.read_csv(base_path + sub_info + \"/\" + d)\n",
    "        data = data.iloc[:, 1:]   # 첫 column(time) 제거\n",
    "        label = get_label_from_filename(l)\n",
    "        labels.append(np.array([label] * data.shape[0]))\n",
    "        dataset.append(data)\n",
    "        #print(\"\\t\", l, d, \" ====> \", np.array([label] * data.shape[0]).shape, data.shape)\n",
    "\n",
    "    D = np.concatenate(dataset, axis=0)\n",
    "    L = np.concatenate(labels, axis=0)\n",
    "    #print(D.shape, L.shape)\n",
    "\n",
    "    balanced_idx = modules.Downsample_to_balance_class(L)\n",
    "    X_emg_bal, y_bal = D[balanced_idx], L[balanced_idx]\n",
    "    print(\"\\t Balanced EMG:\", X_emg_bal.shape, \"y:\", y_bal.shape)\n",
    "\n",
    "    return X_emg_bal, y_bal\n",
    "\n",
    "\n",
    "def sliding_window(X,y):\n",
    "    num_channels = X.shape[1]\n",
    "    X_tmp, y_tmp = processing.sliding_window_with_labels(X=X, y=y,  window_size=window_size, step_size=step_size)  # (num_windows, win_len, ch)\n",
    "\n",
    "    all_X, all_y = modules.get_X_y_ZC_only(X_tmp, y_tmp)\n",
    "    all_y = modules.y_change_to_int(all_y)\n",
    "    #all_X = all_X.reshape(-1, num_channels, 1)\n",
    "\n",
    "    return all_X, all_y"
   ],
   "id": "de6df5e0b245c490",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:35:20.432968Z",
     "start_time": "2025-08-21T12:35:20.429828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = ['STC', 'WAK', 'STDUP', 'SITDN', 'UPS', 'DNS', 'KLFT', 'TPTO', 'LLF', 'LLB', 'LLS', 'KLCL', 'HS', 'TO', 'LUGF', 'LUGB'] #16 classes\n",
    "class_to_label = {cls: i for i, cls in enumerate(classes)}\n",
    "\n",
    "Features = ['mav', 'var', 'zc', 'iemg', 'wl', 'wamp', 'mavs', 'rms', 'ssc', 'msq', 'v3', 'ld', 'dabs', 'mfl', 'mpr', 'mnf', 'psr', 'arc1', 'arc2', 'arc3', 'arc4', 'cc1', 'cc2', 'cc3', 'cca', 'dwtc1', 'dwtc2', 'dwtpc1', 'dwtpc2', 'dwtpc3']\n",
    "\n",
    "base_path = 'D:/Data/Gait-EMG/SIAT/SIAT_LLMD20230404/'\n",
    "Sub_lst_data = [f\"Sub{i:02d}\"+\"/Data/\" for i in range(1, 41)]\n",
    "Sub_lst_label = [f\"Sub{i:02d}\"+\"/Labels/\" for i in range(1, 41)]\n",
    "window_size, step_size = 400, 20"
   ],
   "id": "ad996cd8a1737515",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Store\n",
    "- To reduce time so that I don't have to run the sliding window/ feature extraction everytime"
   ],
   "id": "e61412d8b56a7617"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for SUB, LAB in zip(Sub_lst_data, Sub_lst_label):\n",
    "\n",
    "    data_lst = os.listdir(base_path + SUB)\n",
    "    label_lst = os.listdir(base_path + LAB)\n",
    "    X_target, y_target = get_data(SUB, data_lst, label_lst)\n",
    "    #X_target, y_target = modules.random_downsample_Num(X_target, y_target, n_keep=1000)\n",
    "    print(f\"Sub: {SUB} Start ==> (X, y:) {X_target.shape, y_target.shape} \\n======================================================\\n\")\n",
    "    X_store, y_store = sliding_window(X_target, y_target)\n",
    "    pd.DataFrame(X_store).to_csv(f\"./stored_dataset/X_{SUB[:-6]}.csv\", index=False)\n",
    "    pd.DataFrame(y_store).to_csv(f\"./stored_dataset/y_{SUB[:-6]}.csv\", index=False)"
   ],
   "id": "71d1988ab0fabe63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Baseline - LOSO",
   "id": "8e6daabb70bbf6a6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-21T12:35:24.751254Z"
    }
   },
   "source": [
    "stored_data_path = 'C:/Users/hml76/PycharmProjects/Cross-motor-decoding/Data/Gait3/stored_dataset/'\n",
    "\n",
    "ACC_lst = []\n",
    "for SUB, LAB in zip(Sub_lst_data, Sub_lst_label):\n",
    "\n",
    "    X_target = pd.read_csv(stored_data_path+f'X_{SUB[:-6]}.csv')\n",
    "    y_target = pd.read_csv(stored_data_path+f'y_{SUB[:-6]}.csv')\n",
    "    X_target, y_target = np.array(X_target), np.array(y_target)\n",
    "    num_channels = X_target.shape[1]\n",
    "    X_target = X_target.reshape(-1, num_channels, 1)\n",
    "\n",
    "    #X_target, y_target = modules.random_downsample_Num(X_target, y_target, n_keep=1000)\n",
    "    print(f\"Sub: {SUB} Start ==> (X, y:) {X_target.shape, y_target.shape} \\n======================================================\\n\")\n",
    "\n",
    "    X_lst, y_lst, Sub_acc = [], [], []\n",
    "    for SUB2, LAB2 in zip(Sub_lst_data, Sub_lst_label):\n",
    "        if SUB == SUB2:\n",
    "            continue\n",
    "        else:\n",
    "            X = pd.read_csv(stored_data_path+f'X_{SUB2[:-6]}.csv')\n",
    "            y = pd.read_csv(stored_data_path+f'y_{SUB2[:-6]}.csv')\n",
    "            X, y = np.array(X), np.array(y)\n",
    "            num_channels = X.shape[1]\n",
    "            X = X.reshape(-1, num_channels, 1)\n",
    "            #X_tmp, y_tmp = modules.random_downsample_Num(X_tmp, y_tmp, n_keep=5000)\n",
    "\n",
    "            print(\"\\t Current - baseline : \", X.shape, y.shape)\n",
    "\n",
    "            model = Model.build_model_1D(input_shape=X.shape[1:], num_classes=len(np.unique(y)))\n",
    "            history = model.fit(X, y, epochs=50, batch_size=512, verbose=0)\n",
    "            loss, acc = model.evaluate(X_target, y_target, verbose=0)\n",
    "            print(f\"\\t Subject {SUB2} - inter subject acc => {acc*100:.2f}%\")\n",
    "            Sub_acc.append(acc)\n",
    "    ACC_lst.append(Sub_acc)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub: Sub01/Data/ Start ==> (X, y:) ((21712, 25, 1), (21712, 1)) \n",
      "======================================================\n",
      "\n",
      "\t Current - baseline :  (16304, 25, 1) (16304, 1)\n",
      "\t Subject Sub02/Data/ - inter subject acc => 16.11%\n",
      "\t Current - baseline :  (16129, 25, 1) (16129, 1)\n",
      "\t Subject Sub03/Data/ - inter subject acc => 12.61%\n",
      "\t Current - baseline :  (17217, 25, 1) (17217, 1)\n",
      "\t Subject Sub04/Data/ - inter subject acc => 25.39%\n",
      "\t Current - baseline :  (19380, 25, 1) (19380, 1)\n",
      "\t Subject Sub05/Data/ - inter subject acc => 14.69%\n",
      "\t Current - baseline :  (18993, 25, 1) (18993, 1)\n",
      "\t Subject Sub06/Data/ - inter subject acc => 13.07%\n",
      "\t Current - baseline :  (17449, 25, 1) (17449, 1)\n",
      "\t Subject Sub07/Data/ - inter subject acc => 24.19%\n",
      "\t Current - baseline :  (17858, 25, 1) (17858, 1)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ACC_lst",
   "id": "8170eaffd7dd75f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ba24874e38d04d4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inter-subject : Accumulate",
   "id": "51a2246aae8af3eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ACC_lst = []\n",
    "for SUB, LAB in zip(Sub_lst_data, Sub_lst_label):\n",
    "    print(f\"Sub: {SUB} Start\\n==================================\\n\")\n",
    "    data_lst = os.listdir(base_path + SUB)\n",
    "    label_lst = os.listdir(base_path + LAB)\n",
    "    X_target, y_target = get_data(SUB, data_lst, label_lst)\n",
    "\n",
    "    X_lst, y_lst, Sub_acc = [], [], []\n",
    "    for SUB2, LAB2 in zip(Sub_lst_data, Sub_lst_label):\n",
    "        if SUB == SUB2:\n",
    "            continue\n",
    "        else:\n",
    "            data_lst2 = os.listdir(base_path + SUB2)\n",
    "            label_lst2 = os.listdir(base_path + LAB2)\n",
    "            X_tmp, y_tmp = get_data(SUB2, data_lst2, label_lst2)\n",
    "            X_lst.append(X_tmp)\n",
    "            y_lst.append(y_tmp)\n",
    "            X, y = np.concatenate(X_lst, axis=0), np.concatenate(y_lst, axis=0)\n",
    "            print(\"\\t Cumulated : \", X.shape, y.shape)\n",
    "\n",
    "            model = Model.build_model_1D(input_shape=X.shape[1:], num_classes=len(np.unique(y)))\n",
    "            history = model.fit(X, y, epochs=50, batch_size=512, verbose=0)\n",
    "            loss, acc = model.evaluate(X_target, y_target, verbose=0)\n",
    "            print(f\"\\t Subject {SUB2} - inter subject acc => {acc*100:.2f}%\")\n",
    "            Sub_acc.append(acc)\n",
    "    ACC_lst.append(Sub_acc)"
   ],
   "id": "aed5dbc6d46c9b57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f6f5e838d26da510"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Few-shot adaptation",
   "id": "8ffa4140066974d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e82281720218798b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
